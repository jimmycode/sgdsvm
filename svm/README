





PREPROCESSING THE DATA.

Program <preprocess> reads the RCV1-V2 files in directory ../data/rcv1/
The four official test files become the training set.
The official training file becomes the testing set.
All the TF/IDF things are recomputed accordingly.
The program outputs four sizeable files:

train.bin.gz
train.dat.gz
  Compressed training data in both binary and svmlight formats.
  There are 781265 training documents:
  370541 positives and 410724 negatives.
  The examples in this file are randomly shuffled.

test.bin.gz
test.dat.gz
  Compressed testing data in both binary and svmlight formats.
  There are 23149 testing documents:
  10786 positives and 12363 negatives.

Consistent with the SvmPerf and Pegasos experiments, 
we only use the 47152 features that are present in 
both the training set and the testing set.
The programs report 47153 features because we
start numbering features at 1 for compatibility
with the svmlight suite.




============ HINGE LOSS CLASSIFICATION




SVMSGD


$ ./svmsgd  train.bin.gz test.bin.gz
# Loading train.bin.gz.
# Read 370541+410724=781265 examples.
# Number of features 47153.
# Loading test.bin.gz.
# Read 10786+12363=23149 examples.
# --------- Epoch 1.
# Training on [0, 781264].
# Norm: 1146.05, Bias: 0.0749107
# Total training time 0.32 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.667%.
# train: Cost: 0.227903108159.
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.018%.
# test:  Cost: 0.244467994024.
# --------- Epoch 2.
# Training on [0, 781264].
# Norm: 1142.41, Bias: 0.0742904
# Total training time 0.64 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.659%.
# train: Cost: 0.227650621758.
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.043%.
# test:  Cost: 0.244297508184.
# --------- Epoch 3.
# Training on [0, 781264].
# Norm: 1141.34, Bias: 0.0729949
# Total training time 0.95 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.661%.
# train: Cost: 0.227573630947.
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.026%.
# test:  Cost: 0.244222153757.




$ ./svmsgd2 train.bin.gz test.bin.gz
# Loading train.bin.gz.
# Read 370541+410724=781265 examples.
# Number of features 47153.
# Loading test.bin.gz.
# Read 10786+12363=23149 examples.
# Estimating sparsity and bscale.
#  using 113238 examples.
#  skip: 9935 bscale: 0.00883119
# --------- Epoch 1.
# Training on [0, 781264].
# Norm: 1144.76, Bias: 0.0750328
# Total training time 0.28 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.675%.
# train: Cost: 0.227903118285.
# train: Mincost: 0.227903118285
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.035%.
# test:  Cost: 0.24440020023.
# test:  Mincost: 0.227903118285
# --------- Epoch 2.
# Training on [0, 781264].
# Norm: 1142.96, Bias: 0.0739744
# Total training time 0.56 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.661%.
# train: Cost: 0.227642787389.
# train: Mincost: 0.227642787389
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.056%.
# test:  Cost: 0.244264197418.
# test:  Mincost: 0.227642787389
# --------- Epoch 3.
# Training on [0, 781264].
# Norm: 1142.73, Bias: 0.0730348
# Total training time 0.83 secs.
# train: Testing on [0, 781264].
# train: Misclassification: 5.661%.
# train: Cost: 0.227575207101.
# train: Mincost: 0.227575207101
# test:  Testing on [0, 23148].
# test:  Misclassification: 6.022%.
# test:  Cost: 0.244218563281.
# test:  Mincost: 0.227575207101



COMPARATIVE TIMINGS

$ svm_perf -c 100 train.dat svmperf.model
duration: 66 seconds.
test error: 6.0348%
optimum: 0.2268 (within 1% of svmsgd - issues with c?)


$ svm_light -c .1280  train.dat svmlight.model
duration: 
test error comparison: 
optimum comparison: 







============ SQUARED HINGE LOSS CLASSIFICATION





COMPARATIVE TIMINGS

$ svmlin -A1 -W2e-4  train.x.dat train.y.dat
duration: 276 seconds
test error: 5.34%