
Results with crfsgd2:
---------------------

leonb@ml28:~/sgd/crf$ ./crfsgd2  -c 1 -f 3 -h 5 model.gz template \
  ../data/conll2000/train.txt.gz \
  ../data/conll2000/test.txt.gz

Reading template file template.
  u-templates: 19  b-templates: 1
Scanning ../data/conll2000/train.txt.gz to build dictionary.
  sentences: 8936  outputs: 22
  cutoff: 3  features: 76329  parameters: 1679700
  duration: 6.68 seconds.
Using c=1, i.e. lambda=0.000111907
Reading and preprocessing ../data/conll2000/train.txt.gz.
  processed: 8936 sentences.
  duration: 6.82 seconds.
Reading and preprocessing ../data/conll2000/test.txt.gz.
  processed: 2012 sentences.
  duration: 1.52 seconds.
Initial eta=0.2 t0=44680  total time: 5.68 seconds
[Epoch 1] -- skip=1862.2  wnorm: 7577.97  total time: 13.75 seconds
[Epoch 2] -- skip=1862.2  wnorm: 9856.79  total time: 21.7 seconds
[Epoch 3] -- skip=1862.2  wnorm: 10906.4  total time: 29.73 seconds
[Epoch 4] -- skip=1862.2  wnorm: 11369.3  total time: 37.81 seconds
[Epoch 5] -- skip=1862.2  wnorm: 11554.3  total time: 45.95 seconds
Training perf:  sentences: 8936  loss: 5783.14  obj*n: 11560.3  misses: 2032(0.959726%)
accuracy:  99.04%; precision:  98.29%; recall:  98.44%; FB1:  98.36
Testing perf:  sentences: 2012  loss: 5083.47  obj*n: 6384.24  misses: 2055(4.33755%)
accuracy:  95.66%; precision:  93.09%; recall:  93.34%; FB1:  93.22
[Epoch 6] -- skip=1862.2  wnorm: 11630  total time: 54.14 seconds
[Epoch 7] -- skip=1862.2  wnorm: 11633.2  total time: 62.3 seconds
[Epoch 8] -- skip=1862.2  wnorm: 11624.8  total time: 70.47 seconds
[Epoch 9] -- skip=1862.2  wnorm: 11578.4  total time: 78.65 seconds
[Epoch 10] -- skip=1862.2  wnorm: 11542.5  total time: 86.84 seconds
Training perf:  sentences: 8936  loss: 4082.95  obj*n: 9854.19  misses: 997(0.470889%)
accuracy:  99.53%; precision:  99.22%; recall:  99.02%; FB1:  99.12
Testing perf:  sentences: 2012  loss: 4688.19  obj*n: 5987.62  misses: 1935(4.08426%)
accuracy:  95.92%; precision:  93.71%; recall:  93.44%; FB1:  93.57
[Epoch 11] -- skip=1862.2  wnorm: 11499.3  total time: 95.07 seconds
[Epoch 12] -- skip=1862.2  wnorm: 11458.6  total time: 103.27 seconds
[Epoch 13] -- skip=1862.2  wnorm: 11418.9  total time: 111.48 seconds
[Epoch 14] -- skip=1862.2  wnorm: 11387.6  total time: 119.68 seconds
[Epoch 15] -- skip=1862.2  wnorm: 11358.6  total time: 127.88 seconds
Training perf:  sentences: 8936  loss: 3801.66  obj*n: 9480.97  misses: 656(0.309833%)
accuracy:  99.69%; precision:  99.42%; recall:  99.37%; FB1:  99.40
Testing perf:  sentences: 2012  loss: 4578.93  obj*n: 5857.66  misses: 1942(4.09904%)
accuracy:  95.90%; precision:  93.64%; recall:  93.51%; FB1:  93.57
[Epoch 16] -- skip=1862.2  wnorm: 11329.6  total time: 136.13 seconds
[Epoch 17] -- skip=1862.2  wnorm: 11300  total time: 144.33 seconds
[Epoch 18] -- skip=1862.2  wnorm: 11274.5  total time: 152.53 seconds
[Epoch 19] -- skip=1862.2  wnorm: 11252.6  total time: 160.75 seconds
[Epoch 20] -- skip=1862.2  wnorm: 11228.5  total time: 168.97 seconds
Training perf:  sentences: 8936  loss: 3757.56  obj*n: 9371.82  misses: 626(0.295664%)
accuracy:  99.70%; precision:  99.46%; recall:  99.35%; FB1:  99.40
Testing perf:  sentences: 2012  loss: 4542.36  obj*n: 5806.45  misses: 1874(3.95551%)
accuracy:  96.04%; precision:  93.94%; recall:  93.59%; FB1:  93.76
[Epoch 21] -- skip=1862.2  wnorm: 11210.5  total time: 177.24 seconds
[Epoch 22] -- skip=1862.2  wnorm: 11188.8  total time: 185.46 seconds
[Epoch 23] -- skip=1862.2  wnorm: 11169.8  total time: 193.68 seconds
[Epoch 24] -- skip=1862.2  wnorm: 11151.3  total time: 201.9 seconds
[Epoch 25] -- skip=1862.2  wnorm: 11133.8  total time: 210.12 seconds
Training perf:  sentences: 8936  loss: 3778.94  obj*n: 9345.83  misses: 536(0.253156%)
accuracy:  99.75%; precision:  99.55%; recall:  99.41%; FB1:  99.48
Testing perf:  sentences: 2012  loss: 4520.98  obj*n: 5774.4  misses: 1925(4.06315%)
accuracy:  95.94%; precision:  93.83%; recall:  93.41%; FB1:  93.62
[Epoch 26] -- skip=1862.2  wnorm: 11119.1  total time: 218.42 seconds
[Epoch 27] -- skip=1862.2  wnorm: 11105.2  total time: 226.65 seconds
[Epoch 28] -- skip=1862.2  wnorm: 11090.2  total time: 234.88 seconds
[Epoch 29] -- skip=1862.2  wnorm: 11078.4  total time: 243.11 seconds
[Epoch 30] -- skip=1862.2  wnorm: 11067.2  total time: 251.34 seconds
Training perf:  sentences: 8936  loss: 3766.79  obj*n: 9300.37  misses: 581(0.27441%)
accuracy:  99.73%; precision:  99.50%; recall:  99.41%; FB1:  99.46
Testing perf:  sentences: 2012  loss: 4541.81  obj*n: 5787.74  misses: 1934(4.08215%)
accuracy:  95.92%; precision:  93.60%; recall:  93.56%; FB1:  93.58
[Epoch 31] -- skip=1862.2  wnorm: 11054.6  total time: 259.6 seconds
[Epoch 32] -- skip=1862.2  wnorm: 11042.7  total time: 267.82 seconds
[Epoch 33] -- skip=1862.2  wnorm: 11031.6  total time: 276.03 seconds
[Epoch 34] -- skip=1862.2  wnorm: 11021.6  total time: 284.24 seconds
[Epoch 35] -- skip=1862.2  wnorm: 11012.8  total time: 292.45 seconds
Training perf:  sentences: 8936  loss: 3739.27  obj*n: 9245.69  misses: 514(0.242765%)
accuracy:  99.76%; precision:  99.54%; recall:  99.48%; FB1:  99.51
Testing perf:  sentences: 2012  loss: 4487.62  obj*n: 5727.42  misses: 1901(4.0125%)
accuracy:  95.99%; precision:  93.79%; recall:  93.59%; FB1:  93.69
[Epoch 36] -- skip=1862.2  wnorm: 11004.2  total time: 300.73 seconds
[Epoch 37] -- skip=1862.2  wnorm: 10993.7  total time: 308.95 seconds
[Epoch 38] -- skip=1862.2  wnorm: 10984.3  total time: 317.17 seconds
[Epoch 39] -- skip=1862.2  wnorm: 10977.5  total time: 325.38 seconds
[Epoch 40] -- skip=1862.2  wnorm: 10969.1  total time: 333.6 seconds
Training perf:  sentences: 8936  loss: 3723.08  obj*n: 9207.61  misses: 483(0.228124%)
accuracy:  99.77%; precision:  99.58%; recall:  99.48%; FB1:  99.53
Testing perf:  sentences: 2012  loss: 4472.45  obj*n: 5707.32  misses: 1918(4.04838%)
accuracy:  95.95%; precision:  93.68%; recall:  93.59%; FB1:  93.64
[Epoch 41] -- skip=1862.2  wnorm: 10961.8  total time: 341.86 seconds
[Epoch 42] -- skip=1862.2  wnorm: 10955.3  total time: 350.09 seconds
[Epoch 43] -- skip=1862.2  wnorm: 10947.9  total time: 358.33 seconds
[Epoch 44] -- skip=1862.2  wnorm: 10941.1  total time: 366.57 seconds
[Epoch 45] -- skip=1862.2  wnorm: 10934  total time: 374.8 seconds
Training perf:  sentences: 8936  loss: 3725.38  obj*n: 9192.38  misses: 447(0.211121%)
accuracy:  99.79%; precision:  99.61%; recall:  99.53%; FB1:  99.57
Testing perf:  sentences: 2012  loss: 4478.9  obj*n: 5709.83  misses: 1880(3.96817%)
accuracy:  96.03%; precision:  93.87%; recall:  93.63%; FB1:  93.75
[Epoch 46] -- skip=1862.2  wnorm: 10927.3  total time: 383.09 seconds
[Epoch 47] -- skip=1862.2  wnorm: 10922.8  total time: 391.32 seconds
[Epoch 48] -- skip=1862.2  wnorm: 10916.7  total time: 399.56 seconds
[Epoch 49] -- skip=1862.2  wnorm: 10910.4  total time: 407.8 seconds
[Epoch 50] -- skip=1862.2  wnorm: 10905.6  total time: 416.03 seconds
Training perf:  sentences: 8936  loss: 3718.23  obj*n: 9171.01  misses: 493(0.232847%)
accuracy:  99.77%; precision:  99.56%; recall:  99.49%; FB1:  99.53
Testing perf:  sentences: 2012  loss: 4477.97  obj*n: 5705.7  misses: 1900(4.01038%)
accuracy:  95.99%; precision:  93.73%; recall:  93.65%; FB1:  93.69
Saving model file model.gz.
Done!  416.03 seconds.



Results with crfsgdqn:
----------------------


leonb@ml28:~/sgd/crf$ ./crfsgdqn -c 1 -f 3 -h 5 model.gz template \
     ../data/conll2000/train.txt.gz \
     ../data/conll2000/test.txt.gz

<changed>


Results with crfasgd:
---------------------


leonb@ml28:~/sgd/crf$  ./crfasgd  -c 1 -f 3 -h 5 model.gz template \
  ../data/conll2000/train.txt.gz \
  ../data/conll2000/test.txt.gz

Reading template file template.
  u-templates: 19  b-templates: 1
Scanning ../data/conll2000/train.txt.gz to build dictionary.
  sentences: 8936  outputs: 22
  cutoff: 3  features: 76329  parameters: 1679700
  duration: 6.65 seconds.
Using c=1, i.e. lambda=0.000111907
Reading and preprocessing ../data/conll2000/train.txt.gz.
  processed: 8936 sentences.
  duration: 6.72 seconds.
Reading and preprocessing ../data/conll2000/test.txt.gz.
  processed: 2012 sentences.
  duration: 1.51 seconds.
Initial eta=0.1 t0=89360 etop=516.841  total time: 0 seconds
[Epoch 1] --  wnorm: 3499.3  anorm: 3471.26  total time: 9.2 seconds
[Epoch 2] --  wnorm: 5108.33  anorm: 5085.21  total time: 18.27 seconds
[Epoch 3] --  wnorm: 6256.45  anorm: 5790.58  total time: 27.28 seconds
[Epoch 4] --  wnorm: 7099.84  anorm: 6244.35  total time: 36.29 seconds
[Epoch 5] --  wnorm: 7730.67  anorm: 6624.78  total time: 45.29 seconds
Training perf [w]: sentences: 8936  loss: 7004.41  obj*n: 10869.7  miss: 2556 (1.2%)
accuracy:  98.79%; precision:  98.15%; recall:  97.73%; FB1:  97.94
Training perf [a]: sentences: 8936  loss: 6959.9  obj*n: 10272.3  miss: 2411 (1.13%)
accuracy:  98.86%; precision:  98.06%; recall:  97.86%; FB1:  97.96
Testing perf: sentences: 2012  loss: 4473.83  obj*n: 5219.64  miss: 1869 (3.94%)
accuracy:  96.06%; precision:  93.82%; recall:  93.62%; FB1:  93.72
[Epoch 6] --  wnorm: 8193.77  anorm: 6944.65  total time: 54.34 seconds
[Epoch 7] --  wnorm: 8551.76  anorm: 7207.62  total time: 63.34 seconds
[Epoch 8] --  wnorm: 8837.01  anorm: 7439.23  total time: 72.36 seconds
[Epoch 9] --  wnorm: 9058.89  anorm: 7637.54  total time: 81.38 seconds
[Epoch 10] --  wnorm: 9226.33  anorm: 7807.49  total time: 90.39 seconds
Training perf [w]: sentences: 8936  loss: 5095.16  obj*n: 9708.33  miss: 1321 (0.62%)
accuracy:  99.38%; precision:  98.99%; recall:  98.67%; FB1:  98.83
Training perf [a]: sentences: 8936  loss: 5652.02  obj*n: 9555.77  miss: 1647 (0.77%)
accuracy:  99.22%; precision:  98.65%; recall:  98.48%; FB1:  98.56
Testing perf: sentences: 2012  loss: 4444.97  obj*n: 5323.92  miss: 1877 (3.96%)
accuracy:  96.04%; precision:  93.85%; recall:  93.64%; FB1:  93.74
[Epoch 11] --  wnorm: 9354.98  anorm: 7956.31  total time: 99.44 seconds
[Epoch 12] --  wnorm: 9468.13  anorm: 8090.43  total time: 108.46 seconds
[Epoch 13] --  wnorm: 9552.7  anorm: 8210.35  total time: 117.48 seconds
[Epoch 14] --  wnorm: 9620.03  anorm: 8318.01  total time: 126.5 seconds
[Epoch 15] --  wnorm: 9680.03  anorm: 8408.24  total time: 135.51 seconds
Training perf [w]: sentences: 8936  loss: 4564.14  obj*n: 9404.15  miss: 1027 (0.48%)
accuracy:  99.51%; precision:  99.17%; recall:  98.96%; FB1:  99.07
Training perf [a]: sentences: 8936  loss: 5120.98  obj*n: 9325.1  miss: 1332 (0.62%)
accuracy:  99.37%; precision:  98.90%; recall:  98.75%; FB1:  98.82
Testing perf: sentences: 2012  loss: 4441.75  obj*n: 5388.34  miss: 1866 (3.93%)
accuracy:  96.06%; precision:  93.89%; recall:  93.68%; FB1:  93.79
[Epoch 16] --  wnorm: 9723.36  anorm: 8484.86  total time: 144.58 seconds
[Epoch 17] --  wnorm: 9758.74  anorm: 8564.28  total time: 153.58 seconds
[Epoch 18] --  wnorm: 9791.49  anorm: 8625.81  total time: 162.6 seconds
[Epoch 19] --  wnorm: 9815.4  anorm: 8681.34  total time: 171.61 seconds
[Epoch 20] --  wnorm: 9836.39  anorm: 8739.09  total time: 180.62 seconds
Training perf [w]: sentences: 8936  loss: 4530.59  obj*n: 9448.78  miss: 829 (0.39%)
accuracy:  99.61%; precision:  99.23%; recall:  99.29%; FB1:  99.26
Training perf [a]: sentences: 8936  loss: 4853.37  obj*n: 9222.92  miss: 1171 (0.55%)
accuracy:  99.45%; precision:  99.02%; recall:  98.87%; FB1:  98.95
Testing perf: sentences: 2012  loss: 4437.82  obj*n: 5421.65  miss: 1875 (3.95%)
accuracy:  96.04%; precision:  93.87%; recall:  93.67%; FB1:  93.77
[Epoch 21] --  wnorm: 9853.96  anorm: 8789.55  total time: 189.69 seconds
[Epoch 22] --  wnorm: 9864.61  anorm: 8838.59  total time: 198.68 seconds
[Epoch 23] --  wnorm: 9876.23  anorm: 8874.35  total time: 207.67 seconds
[Epoch 24] --  wnorm: 9883.93  anorm: 8919.72  total time: 216.66 seconds
[Epoch 25] --  wnorm: 9890.4  anorm: 8960.27  total time: 225.66 seconds
Training perf [w]: sentences: 8936  loss: 4393.73  obj*n: 9338.93  miss: 790 (0.37%)
accuracy:  99.63%; precision:  99.33%; recall:  99.22%; FB1:  99.27
Training perf [a]: sentences: 8936  loss: 4688.21  obj*n: 9168.35  miss: 1064 (0.5%)
accuracy:  99.50%; precision:  99.10%; recall:  98.96%; FB1:  99.03
Testing perf: sentences: 2012  loss: 4436.42  obj*n: 5445.16  miss: 1874 (3.95%)
accuracy:  96.04%; precision:  93.86%; recall:  93.69%; FB1:  93.77
[Epoch 26] --  wnorm: 9897.67  anorm: 8999.82  total time: 234.75 seconds
[Epoch 27] --  wnorm: 9903.04  anorm: 9023.6  total time: 243.79 seconds
[Epoch 28] --  wnorm: 9907.18  anorm: 9052.95  total time: 252.83 seconds
[Epoch 29] --  wnorm: 9905.46  anorm: 9089.79  total time: 261.88 seconds
[Epoch 30] --  wnorm: 9908.79  anorm: 9117.71  total time: 270.92 seconds
Training perf [w]: sentences: 8936  loss: 4293  obj*n: 9247.39  miss: 711 (0.33%)
accuracy:  99.66%; precision:  99.37%; recall:  99.32%; FB1:  99.35
Training perf [a]: sentences: 8936  loss: 4577.49  obj*n: 9136.34  miss: 987 (0.46%)
accuracy:  99.53%; precision:  99.16%; recall:  99.02%; FB1:  99.09
Testing perf: sentences: 2012  loss: 4435.43  obj*n: 5461.89  miss: 1873 (3.95%)
accuracy:  96.05%; precision:  93.86%; recall:  93.70%; FB1:  93.78
[Epoch 31] --  wnorm: 9912.22  anorm: 9139.2  total time: 279.99 seconds
[Epoch 32] --  wnorm: 9909.08  anorm: 9155.86  total time: 289.01 seconds
[Epoch 33] --  wnorm: 9913.94  anorm: 9169.44  total time: 298.05 seconds
[Epoch 34] --  wnorm: 9910.42  anorm: 9181.57  total time: 307.08 seconds
[Epoch 35] --  wnorm: 9911.8  anorm: 9193.48  total time: 316.12 seconds
Training perf [w]: sentences: 8936  loss: 4265.99  obj*n: 9221.89  miss: 724 (0.34%)
accuracy:  99.66%; precision:  99.39%; recall:  99.25%; FB1:  99.32
Training perf [a]: sentences: 8936  loss: 4518.65  obj*n: 9115.39  miss: 935 (0.44%)
accuracy:  99.56%; precision:  99.20%; recall:  99.07%; FB1:  99.13
Testing perf: sentences: 2012  loss: 4433.22  obj*n: 5468.21  miss: 1871 (3.94%)
accuracy:  96.05%; precision:  93.87%; recall:  93.72%; FB1:  93.79
[Epoch 36] --  wnorm: 9908.12  anorm: 9206.16  total time: 325.21 seconds
[Epoch 37] --  wnorm: 9907.77  anorm: 9220.84  total time: 334.25 seconds
[Epoch 38] --  wnorm: 9901.89  anorm: 9238.37  total time: 343.26 seconds
[Epoch 39] --  wnorm: 9903.04  anorm: 9259.47  total time: 352.27 seconds
[Epoch 40] --  wnorm: 9897.87  anorm: 9266.02  total time: 361.28 seconds
Training perf [w]: sentences: 8936  loss: 4232.67  obj*n: 9181.6  miss: 753 (0.35%)
accuracy:  99.64%; precision:  99.36%; recall:  99.29%; FB1:  99.33
Training perf [a]: sentences: 8936  loss: 4468.04  obj*n: 9101.05  miss: 885 (0.41%)
accuracy:  99.58%; precision:  99.23%; recall:  99.12%; FB1:  99.17
Testing perf: sentences: 2012  loss: 4432.22  obj*n: 5475.37  miss: 1871 (3.94%)
accuracy:  96.05%; precision:  93.88%; recall:  93.70%; FB1:  93.79
[Epoch 41] --  wnorm: 9899.09  anorm: 9278.25  total time: 370.35 seconds
[Epoch 42] --  wnorm: 9895.01  anorm: 9296.58  total time: 379.37 seconds
[Epoch 43] --  wnorm: 9893.36  anorm: 9302.45  total time: 388.4 seconds
[Epoch 44] --  wnorm: 9891.28  anorm: 9315.89  total time: 397.42 seconds
[Epoch 45] --  wnorm: 9882.25  anorm: 9337.16  total time: 406.43 seconds
Training perf [w]: sentences: 8936  loss: 4213.76  obj*n: 9154.89  miss: 667 (0.31%)
accuracy:  99.68%; precision:  99.43%; recall:  99.29%; FB1:  99.36
Training perf [a]: sentences: 8936  loss: 4422.95  obj*n: 9091.53  miss: 842 (0.39%)
accuracy:  99.60%; precision:  99.27%; recall:  99.15%; FB1:  99.21
Testing perf: sentences: 2012  loss: 4431.77  obj*n: 5482.93  miss: 1872 (3.95%)
accuracy:  96.05%; precision:  93.87%; recall:  93.70%; FB1:  93.78
[Epoch 46] --  wnorm: 9886.92  anorm: 9347.61  total time: 415.5 seconds
[Epoch 47] --  wnorm: 9883.96  anorm: 9367.11  total time: 424.54 seconds
[Epoch 48] --  wnorm: 9877.1  anorm: 9376.82  total time: 433.57 seconds
[Epoch 49] --  wnorm: 9878.85  anorm: 9377.16  total time: 442.61 seconds
[Epoch 50] --  wnorm: 9874.28  anorm: 9388.14  total time: 451.64 seconds
Training perf [w]: sentences: 8936  loss: 4235.68  obj*n: 9172.81  miss: 681 (0.32%)
accuracy:  99.68%; precision:  99.40%; recall:  99.33%; FB1:  99.36
Training perf [a]: sentences: 8936  loss: 4390.43  obj*n: 9084.5  miss: 818 (0.38%)
accuracy:  99.61%; precision:  99.28%; recall:  99.17%; FB1:  99.23
Testing perf: sentences: 2012  loss: 4431.15  obj*n: 5488.05  miss: 1873 (3.95%)
accuracy:  96.05%; precision:  93.85%; recall:  93.71%; FB1:  93.78
Saving model file model.gz.
Done!  451.64 seconds.
