



RUNNING THE STOCHASTIC GRADIENT CRF ON THE CONLL CHUNKING TASK

The program "crfsgd" uses the same formats as CRF++ for 
template files and data files. These formats are explained
on the CRF++ page http://crfpp.sourceforge.net.
However, the program "crfsgd" wants gzipped data files
instead of plain text files. 


-- Usage.

$ ./crfsgd
Usage (training): crfsgd [options] model template traindata [devdata]
Usage (tagging):  crfsgd -t model testdata
Options for training:
 -c <num> : capacity control parameter (4.0)
 -f <num> : threshold on the occurences of each feature (3)
 -r <num> : total number of epochs (100)
 -h <num> : epochs between each testing phase (10)
 -e <cmd> : performance evaluation command (conlleval -q)
 -q       : silent mode



-- Training the model:
   Performance is evaluated on both sets every 10 epochs.
   This is convenient to see the how testing performance.
   See how the objective function is still decreasing on
   the training set but increasing on the testing set.
   We are already overfitting.  But the F1 scores
   evolve differently because they are not the same
   as the crf objective function. Reweighting examples
   according to their contribution to the F1 score
   would be a smart thing to do...

$ ./crfsgd -c 4.0 model.gz template \ 
        ../data/conll2000/train.txt.gz \
        ../data/conll2000/test.txt.gz
Reading template file template.
<...>
  sentences: 8936  outputs: 22
  cutoff: 3  features: 76329  parameters: 1679700
  duration: 3.7 seconds.
<...>
[Epoch 10] --  wnorm: 9565.97  training time: 127.93 seconds
Training perf:  sentences: 8936  loss: 5304.27  objective*n: 6500.02
accuracy:  99.21%; precision:  98.66%; recall:  98.57%; FB1:  98.62
Testing perf:  sentences: 2012  loss: 4588.06  objective*n: 4857.29
accuracy:  95.88%; precision:  93.61%; recall:  93.48%; FB1:  93.55
<...>
[Epoch 20] --  wnorm: 13700.6  training time: 230.92 seconds
Training perf:  sentences: 8936  loss: 3309.36  objective*n: 5021.94
accuracy:  99.70%; precision:  99.48%; recall:  99.41%; FB1:  99.44
Testing perf:  sentences: 2012  loss: 4705.34  objective*n: 5090.94
accuracy:  95.94%; precision:  93.74%; recall:  93.53%; FB1:  93.63
<...>
[Epoch 30] --  wnorm: 15932.9  training time: 330.99 seconds
Training perf:  sentences: 8936  loss: 2612.54  objective*n: 4604.15
accuracy:  99.83%; precision:  99.70%; recall:  99.66%; FB1:  99.68
Testing perf:  sentences: 2012  loss: 4782.24  objective*n: 5230.66
accuracy:  95.91%; precision:  93.72%; recall:  93.48%; FB1:  93.60
<...>
[Epoch 40] --  wnorm: 17250.8  training time: 429.8 seconds
Training perf:  sentences: 8936  loss: 2278.76  objective*n: 4435.12
accuracy:  99.88%; precision:  99.78%; recall:  99.76%; FB1:  99.77
Testing perf:  sentences: 2012  loss: 4826.23  objective*n: 5311.75
accuracy:  95.92%; precision:  93.73%; recall:  93.47%; FB1:  93.60
<...>
[Epoch 50] --  wnorm: 18081.9  training time: 528.17 seconds
Training perf:  sentences: 8936  loss: 2090.28  objective*n: 4350.52
accuracy:  99.90%; precision:  99.83%; recall:  99.81%; FB1:  99.82
Testing perf:  sentences: 2012  loss: 4851.57  objective*n: 5360.48
accuracy:  95.93%; precision:  93.74%; recall:  93.51%; FB1:  93.62
Saving model file model.gz.
Done!  528.17 seconds.


-- Testing the final model:

$ ./crfsgd model.gz ../data/conll2000/test.txt.gz | ./conlleval
processed 47377 tokens with 23852 phrases; found: 23793 phrases; correct: 22303.
accuracy:  95.93%; precision:  93.74%; recall:  93.51%; FB1:  93.62
             ADJP: precision:  80.75%; recall:  73.74%; FB1:  77.09  400
             ADVP: precision:  82.66%; recall:  80.37%; FB1:  81.50  842
            CONJP: precision:  50.00%; recall:  55.56%; FB1:  52.63  10
             INTJ: precision:  50.00%; recall:  50.00%; FB1:  50.00  2
              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0
               NP: precision:  94.19%; recall:  93.96%; FB1:  94.08  12392
               PP: precision:  97.00%; recall:  97.46%; FB1:  97.23  4834
              PRT: precision:  74.56%; recall:  80.19%; FB1:  77.27  114
             SBAR: precision:  86.42%; recall:  85.61%; FB1:  86.01  530
               VP: precision:  93.68%; recall:  93.90%; FB1:  93.79  4669





COMPARATIVE EXPERIMENTS WITH CRF++

$ crf_learn -c 4.0 -f 3 template train.txt model
Number of sentences: 8936
Number of features:  1679700
 <...skipping...>
iter=199 terr=0.00038 serr=0.00638 act=1679700 obj=4138.23633 diff=0.00009
Done! 6071.06 seconds.

$ crf_test -m model test.txt | tr '	' ' ' | ../../../conlleval 
processed 47377 tokens with 23852 phrases; found: 23809 phrases; correct: 22323
accuracy:  95.95%; precision:  93.76%; recall:  93.59%; FB1:  93.67
             ADJP: precision:  80.24%; recall:  75.11%; FB1:  77.59  410
             ADVP: precision:  83.73%; recall:  80.25%; FB1:  81.96  830
            CONJP: precision:  55.56%; recall:  55.56%; FB1:  55.56  9
             INTJ: precision:  50.00%; recall:  50.00%; FB1:  50.00  2
              LST: precision:   0.00%; recall:   0.00%; FB1:   0.00  0
               NP: precision:  94.11%; recall:  93.96%; FB1:  94.03  12403
               PP: precision:  96.79%; recall:  97.82%; FB1:  97.30  4862
              PRT: precision:  79.25%; recall:  79.25%; FB1:  79.25  106
             SBAR: precision:  87.84%; recall:  85.05%; FB1:  86.42  518
               VP: precision:  93.72%; recall:  93.95%; FB1:  93.84  4669


